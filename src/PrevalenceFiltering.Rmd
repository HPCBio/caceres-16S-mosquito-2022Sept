---
title: "Agglomeration and prevalence filtering"
author: "Chris Fields"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    pdf_print: paged
    fig_height: 6
    fig_width: 12
    toc: yes
    toc_float: yes
---

# Set up

Code (not shown in the report) is initialized and loaded here.  We don't include the code in the report but make this available as needed; please see the [Github repository](https://github.com/HPCBio/flaws-2020March-16S)for this project for the final version.

```{r PrevalenceFiltering-1, echo=TRUE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r PrevalenceFiltering-2, include=FALSE}
# Note that not all libraries will be needed.  Most phyloseq code uses ggplot and tidyverse internally, therefore we explicitly load here
library(knitr)
library(tidyverse)
library(phyloseq)

# this seems to have issues with caching and phyloseq
# library(ggtree) 

# For normalization
library(metagenomeSeq)

# phylogenetic tree input
library(ape)

# read/modify BIOM 
library(biomformat)

# ggplot functions for trees and dendrograms
library(ggdendro)

# distance measures, PERMANOVA, ANOSIM
library(vegan)

# generation of stats values for graphs
library(ggpubr)

# normalization (CLR)
library(mixOmics)

# to get labels2color
library(WGCNA)

# mixed models (needs to be updated)
library(lme4)
library(lmerTest)
library(nlme)

# sample decontamination
library(decontam)

# to get post-hoc tests for mixed-model tests 
library(lsmeans)
library(devtools)

#Other
library(gridExtra)

# needed in case we want to use ANCOM
#library(exactRankTests)

# this is to load some extension helper code, see: https://github.com/HPCBio/phyloseq-extended
devtools::load_all('~/src/phyloseq-extended')
```

```{r PrevalenceFiltering-3, include=FALSE}
# Setting up the analysis, including adding helper functions.  The document won't include the actual code, but the functions are present in the Rmd document.  The functions here include ones to:
options(stringsAsFactors = FALSE)
theme_set(theme_bw())
```

```{r PrevalenceFiltering-4, include=FALSE}
# Remove the tags on the taxonomic ranks, which are redundant with the column headers.
stripTaxaTags <- function(physeq) {
  oldMA <- as(tax_table(physeq), "matrix")
  newMA <- apply(oldMA, 2, function(x) {sub('\\w__','', x)})
  if (inherits(physeq, "taxonomyTable")) {
      return(tax_table(newMA))
  }
  else {
      tax_table(physeq) <- tax_table(newMA)
      return(physeq)
  }
}
```

```{r PrevalenceFiltering-5 }
# Convert sequences to names (culled from https://github.com/LangilleLab/microbiome_helper/blob/master/convert_dada2_out.R) 

renameTaxIds <- function(physeq, file.name="seqs.fasta") {
  suppressMessages(require("ShortRead"))
  seqtab.physeq <- otu_table(physeq)
  seqs <- colnames(seqtab.physeq)
  ids_study <- paste("seq", 1:ncol(seqtab.physeq), sep = "_")
  seqs.dna <- ShortRead(sread = DNAStringSet(seqs), id = BStringSet(ids_study))
  # Write out fasta file.
  writeFasta(seqs.dna, file = file.name)
  taxa_names(physeq) <- ids_study
  # TODO: add the sequences back to the phyloseq instance
  # physeq <- merge_phyloseq(physeq)
  return(physeq)
}
```

```{r PrevalenceFiltering-6}
# original code: https://github.com/twbattaglia/btools/blob/master/R/estimate_pd.R
estimate_pd <- function(phylo) {
  # Error if input is not of class phylo
  if(class(phylo) != "phyloseq"){
    stop("Input file is not of class 'phyloseq'.")
  }

  # Error if no class phy_tree
  if(!(.hasSlot(phylo, "phy_tree"))){
    stop("Could not find tree slot in phylo object.")
  }
  
  if (!require('picante')) stop("Function requires the picante library.")

  # Transpose if needed
  # Adapted from phyloseq/vegan import
  OTU <- phyloseq::otu_table(phylo)
  if (taxa_are_rows(OTU)) {
    OTU <- t(OTU)
  }

  # Get matrix version of OTU table
  otutable <- as(OTU, "matrix")

  # Get phylogenetic tree from phyloseq object
  tree <- phyloseq::phy_tree(phylo)

  # Print status message
  message("Calculating Faiths PD-index...")

  # If object is greater than 10mb, then print status message
  if(object.size(otutable) > 10000000){
    message("This is a large object, it may take awhile...")
  }

  # Calculate Faith's PD-index
  #
  pdtable <- picante::pd(otutable, tree, include.root = F)

  # Return data frame of results
  return(pdtable)
}
```

```{r PrevalenceFiltering-7}
# CLR normalization 
# (from McMurdie (Meth Mol Bio 2018) supplemental package)
zero_comp = function(x){
  if(taxa_are_rows(x)){x <- t(x)}
  matx = otu_table(x)
  # `zCompositions::cmultRepl` expects the samples to be in rows and OTUs to be in columns
  matxzc = zCompositions::cmultRepl(matx, method="CZM", output="p-counts")
  otu_table(x) <- otu_table(matxzc, taxa_are_rows = FALSE)
  return(x)
}
# CLR definition
geometric_mean = function(x){
  exp(mean(log(x)))
}
clr = function(x, base=2){
  x <- log((x / geometric_mean(x)), base)
}
phyloseq_CLR = function(physeq){
  suppressMessages({physeq <- zero_comp(physeq)})
  return(transform_sample_counts(physeq, fun = clr))
}
```

# Load data

Load in the filtered data from part 1:

```{r AlphaDiversity-PacBio-8}
physeq.filtered <- readRDS('../results/phyloseq.filtered.pt1.RDS')
physeq.filtered
```

# Remove poor samples

Based on the prior steps we found that MB8 had very low counts and only one taxa, which isn't useful. Let's remove it.

```{r}
physeq.filtered <- subset_samples(physeq.filtered, SampleID != "MB8")
physeq.filtered
```

We also need to remove any 0-count taxa:

```{r}
physeq.filtered <- prune_taxa(taxa_sums(physeq.filtered) > 0, physeq.filtered)
physeq.filtered
```

# Additional Filtering

We performed some high level filtering to remove artifacts and problematic data. Next step is agglomeration of count data and prevalence filtering.

## Explore taxon data 

What is the range in total counts per taxon?

```{r PrevalenceFiltering-8 }
range(taxa_sums(physeq.filtered))
```

Some taxa with very low counts overall; depending on their prevalence this may be removed.  What does the distribution look like at the low end?

```{r PrevalenceFiltering-9 }
hist(log2(taxa_sums(physeq.filtered)), 1000)
```

What about sample counts?  What is the range in total counts per sample?

```{r PrevalenceFiltering-10 }
range(sample_sums(physeq.filtered))
```

We have some on the low end, with `r sum(sample_sums(physeq.filtered) <= 5000)` samples less than 5k counts.

```{r PrevalenceFiltering-11 }
p <- ggplot(data = data.frame(
    SampleSums = sample_sums(physeq.filtered),
    Names = factor(sample_names(physeq.filtered), ordered = TRUE,
                   levels = sample_names(physeq.filtered)),
    Group = factor(sample_data(physeq.filtered)$Strain, ordered = TRUE)
), aes(y = SampleSums, x = Names, fill = Group))
p <- p + geom_bar(stat = 'identity' )
p <- p + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p
```

MB5 and MB8 are the lowest count sample, with MB8 to be excluded.

How do the ASV counts correlate with the read counts?

```{r PrevalenceFiltering-12 }
myData <- data.frame(
  Name = sample_names(physeq.filtered),
  OTUSums = sample_sums(physeq.filtered),
  Reads = as.numeric(sample_data(physeq.filtered)$input),
  Group = sample_data(physeq.filtered)$Strain
)
p <- ggplot(data = myData, aes(x = Reads, y = OTUSums))
p <- p + geom_smooth(method = "gam", color = "lightgreen")
p <- p + geom_smooth(method = "lm", color = "lightblue")
p <- p + geom_point(aes(color = Group))
p
```

Fairly significant shift from a linear fit, there seems to be a skew with higher count (light green line).

Next we filter based on the features prevalent in the samples.  We will also switch the order of the filtering and tree-based (tip) agglomeration steps due to the nature of PacBio data (noisier at the tips); this is something we're discussing within the group. It may be strain-level variation that is difficult to assign.

## Tip agglomeration

What does the current tree look like?

```{r PrevalenceFiltering-13}
p <- plot_tree(physeq.filtered, 
          nodelabf = nodeplotblank, 
          color="Sample", 
          ladderize = "left", 
          method = "treeonly") +
  ggtitle(paste0("Original tree: ", ntaxa(physeq.filtered), " taxa")) +
  theme(plot.title = element_text(size = 10))
library(plotly)

ggplotly(p)
```

Zooming into the tips indicates there are a many sequences with very small differences.  

```{r PrevalenceFiltering-14}
hist(log(phy_tree(physeq.filtered)$edge.length), 
     xlab = "Edge Length (log)", 
     main = "Edge length distribution")
```

### Clip out long branches

There are a few long branches that we need to check

```{r PrevalenceFiltering-14.B}
tmp <- phy_tree(physeq.filtered)

# grab the tip lengths and format for ggplot
treeTips <- data.frame(
  ID = tmp$tip.label,
  Tip.Length = tmp$edge.length[tmp$edge[,2] <= Ntip(tmp)]
)

p <- treeTips %>%
  ggplot( aes(x=Tip.Length, fill = "black")) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity', bins = 100)

ggplotly(p)
```

You have to zoom into the right a bit and look at the frequencies accordingly:

```{r}
p + xlim(0.1, 1) + ylim(0,10)
```

Several stand out with very long tip lengths. What are they?

```{r}
longbranch <- treeTips[order(treeTips$Tip.Length, decreasing = TRUE)[1:31],]

tmp2 <- cbind(tax_table(physeq.filtered), as.data.frame(taxa_sums(physeq.filtered)))

knitr::kable(tmp2[longbranch$ID,])
```

These look real! I think we leave them as is.

What samples are these in?

```{r}
tmp <-suppressWarnings(prune_taxa(taxa_names(physeq.filtered) %in% longbranch$ID,
                  physeq.filtered))

ssums <- sample_sums(tmp)
ssums[ssums > 0]
```

They are spread across samples as well.

### Plot cophenetic distances

Agglomeration is based on the cophenetic distance, the pairwise distances between tips on the tree. These are pretty short; let's see what that distribution looks like

```{r PrevalenceFiltering-15}
cp_phylo <- cophenetic.phylo(phy_tree(physeq.filtered))

hist(cp_phylo, 
     breaks = 100, 
     main = "Pairwise distance between tips", 
     xlab = "Distance between tips")

cutoff <- c(seq(0.025, 0.15, 0.025), 0.2, 0.3, 0.5, 0.75, 1, 2)
abline(v=cutoff, col = "red")
text(cutoff, max(hist(cp_phylo, 100, plot=FALSE)$counts), labels = cutoff, pos = 2, srt = 90, cex = .5 )
```

Note those at the high end of distance, probably out off-shoot group. We do not see those in the merged data!

The red lines are some arbitrary test cutoffs. Based on the above we could use 0.3 (right after the small shoulder to the far left).  There are additional valleys around 0.5 and higher, but we could stay with the above threshold for now.

Let's replot in log scale.  

```{r PrevalenceFiltering-16}
hist(log(cp_phylo), 
     breaks = 100, 
     main = "Pairwise distance between tips", 
     xlab = "Distance between tips (log)", 
     xlim = c(-5, 5))

abline(v=log(cutoff), col = "red")
text(log(cutoff), max(hist(log(cp_phylo), 100, plot=FALSE)$counts), labels = cutoff, pos = 2, srt = 90, cex = .5 )
```

I think 0.3 or 0.5 is fine for now if we choose tip agglomeration.

<!-- ```{r PrevalenceFiltering-17} -->
<!-- # Use the cutoffs listed above -->

<!-- # this takes some time to run :).  There is a speedyseq package with a faster tip_glom implementation, might be worth checking -->
<!-- pseqs <- lapply(cutoff[1:8], function(x) {speedyseq::tip_glom(physeq.filtered, h = x)}) -->

<!-- names(pseqs) <- cutoff[1:8] -->
<!-- ``` -->

<!-- Note there is a `phyloseq` instance with no tree now. Let's only plot the ones that have a tree.  -->

<!-- ```{r PrevalenceFiltering-18} -->
<!-- # In order to screen for instances with a tree we need to use tryCatch as checking the tree slot with phy_tree will error if it is NULL) -->

<!-- pseqs.final <- pseqs[sapply(pseqs, function(x) { -->
<!--   !is.null( tryCatch({phy_tree(x)}, error = function(cond) { return(NULL) }) ) -->
<!--   }, simplify = TRUE)] -->

<!-- plots <- sapply(names(pseqs.final), function(x) { -->
<!--   plot_tree(pseqs.final[[x]],  -->
<!--           nodelabf = nodeplotblank, -->
<!--           ladderize = "left",  -->
<!--           method = "treeonly") +  -->
<!--   ggtitle(paste0("Height:",x, ", ", ntaxa(pseqs.final[[x]]), " taxa")) +  -->
<!--     theme(plot.title = element_text(size = 10)) -->
<!--   }, simplify = FALSE -->
<!--   ) -->

<!-- grid.arrange(grobs = prepend(plots, list(Original = p)), -->
<!--              nrow = 3) -->

<!-- ``` -->

<!-- Quite a bit is removed even with the lowest cutoff.  How does that one look? -->

<!-- ```{r PrevalenceFiltering-19} -->
<!-- p <- plot_tree(pseqs.final[['0.025']], -->
<!--           label.tips = "Genus", -->
<!--           ladderize = "left", -->
<!--           justify = "left", -->
<!--           color = 'Treatment') -->
<!-- ``` -->

<!-- ```{r PrevalenceFiltering-20} -->
<!-- #ggplotly(p) -->
<!-- ggplotly(plot_tree(pseqs.final[['0.05']], -->
<!--           # nodelabf = nodeplotblank, -->
<!--           ladderize = "left", -->
<!--           method = "treeonly")) -->
<!-- ``` -->

<!-- One advantage with these methods, we lose essentially no count data from the prior step: -->

<!-- ```{r PrevalenceFiltering-21} -->
<!-- p <- ggplot(data = data.frame( -->
<!--     SampleLoss = sample_sums(pseqs.final[['0.05']]) / sample_sums(physeq.filtered), -->
<!--     Names = factor(sample_names(pseqs.final[['0.05']]), ordered = TRUE, levels = sample_names(pseqs.final[['0.15']])), -->
<!--     Group = factor(sample_data(pseqs.final[['0.05']])$Treatment, ordered = TRUE) -->
<!-- ), aes(y = SampleLoss, x = Names, fill = Group)) -->
<!-- p <- p + geom_bar(stat = 'identity' ) -->
<!-- p <- p + theme(axis.text.x = element_text(angle = 90, hjust = 1)) -->
<!-- p -->
<!-- ``` -->

<!-- We'll pick the 0.2 height cutoff sample for the next steps. -->

<!-- ```{r PrevalenceFiltering-22} -->
<!-- # pseqs <- lapply(cutoff[1:8], function(x) {speedyseq::tip_glom(physeq.filtered, h = x)}) -->
<!-- physeq.glom <- tip_glom(physeq.filtered, h = 0.3) -->
<!-- physeq.glom -->
<!-- ``` -->

## Tax agglomeration

What is the effect of taxonomic agglomeration per rank? Let's do a quick run through on the samples; ranks that are not assigned are removed by default, so let's see what happens.

```{r PrevalenceFiltering-23 }
taxglom_per_rank = function(physeq.glom, rank = "Species") {
  # TODO: add sanity check
  glommedPhyseq <- tax_glom(physeq.glom, taxrank = rank, NArm = TRUE)
  p <- ggplot(data = data.frame(
      SampleLoss = sample_sums(glommedPhyseq) / sample_sums(physeq.filtered),
      Names = factor(sample_names(glommedPhyseq),
                     ordered = TRUE,
                     levels = sample_names(glommedPhyseq)),
      Group = factor(sample_data(glommedPhyseq)$Strain, ordered = TRUE)
  ), aes(y = SampleLoss, x = Names, fill = Group)) +
    geom_bar(stat = 'identity' ) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    ggtitle(paste0("Rank: ", rank))
  return(p)
}
```

```{r PrevalenceFiltering-24 }
tmp <- as(tax_table(physeq.filtered), 'matrix')
tmp[tmp == 'Unclassified'] = NA
tax_table(physeq.filtered) <- tmp
```

```{r}
ranks <- c("Species", "Genus", "Family", "Order")

plots <- lapply(ranks, function(x) {
  p <- taxglom_per_rank(physeq.filtered, rank = x)
  p + theme(legend.position = "none") + expand_limits(y = c(0, 1))
})

grid.arrange(grobs = plots)
```

Wow, quite a bit lost with species!  Are there rows in there with 'NA'?

```{r PrevalenceFiltering-25 }
#apply(tax_table(physeq.glom), 2, function(x) sum(x != "Unclassified"))
apply(tax_table(physeq.filtered), 2, function(x) sum(is.na(x)))
```

We pretty much retain everything if we stick to family.  At the moment I'll likely agglomerate to Family but we can revisit.

<!-- Yes, though not nearly as many as the overall # of taxa. This suggests maybe using the phylogenetic tree and `tip_glom`. We have been seeing this work with better fidelity with more recent data sets, particularly from PacBio sequences, but it does require a little checking on the phylogenetic branch lengths to determine the best cutoff.  The code below is based on work Lindsay Clark and Jenny have done in the group.  -->

<!-- ## Tree glom  -->

<!-- This is a newer but somewhat experimental method implemented in the `speedyseq` package. -->

<!-- ```{r} -->
<!-- #get_pairwise_distances(tree, A, B, as_edge_counts=FALSE, check_input=TRUE) -->
<!-- ``` -->

```{r}
physeq.glom <- tax_glom(physeq.filtered, taxrank = 'Family', NArm = FALSE)
physeq.glom
```

## Features and Prevalence tables

For the filtering, let's assign the original filtered data to a temp variable prior to prevalence filtering.

```{r PrevalenceFiltering-26 }
physeq0 <- physeq.glom
physeq0
```

Suggested based on the Callahan dada2 workflow (F1000Research, 2017).  This is a bit of data exploration to see how many features are present per taxa.

```{r PrevalenceFiltering-27 }
table(tax_table(physeq0)[,"Phylum"], exclude = NULL)
```

A couple are 'NA', which is odd, because these were not present before glom-ing. There are number with low features (1-2 OTUs) as well. Let's remove the NA taxa...

```{r PrevalenceFiltering-28 }
physeq0 <- subset_taxa(physeq0, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
physeq0
```

There is a small difference here. 

Now, let's get an idea how many taxa in the samples have an ASV count greater than 1.  We can make this more or less strict as needed.

```{r PrevalenceFiltering-29 }
# What is this doing?  It calculates a vector with the count being the # samples with a count > 0.

# Note: make sure you are using *raw counts* here; if you use proportional
# counts make sure to adjust the function appropriately
prevdf <- apply(otu_table(physeq0),  # counts
               # use row or column depending on the data
               MARGIN = ifelse(taxa_are_rows(physeq0), yes = 1, no = 2), 
               # how many times the counts in the samples are greater than 0
               FUN = function(x){sum(x > 0)}  
               )
prevdf <- data.frame(Prevalence =  prevdf, # num samples counts are > 0
                     TotalAbundance = taxa_sums(physeq0), # total abundance
                     tax_table(physeq0)) # tax ID and ranks
```

Here is a quick summary of the prevalence results.  These are performed per ASV but summarized at the Phylum rank, with the 

```{r PrevalenceFiltering-30 }
# a quick high level summary at the Phylum rank.
tmp <- plyr::ddply(prevdf, "Phylum", function(df1) { cbind(mean(df1$Prevalence), sum(df1$Prevalence)) })
colnames(tmp) <- c("Phylum", "mean", "sum")
knitr::kable(tmp)
```

Actinos, Proteos, and Firmicutes, with some Bacteroidota.  We can plot these out to get more resolution.  Let's graph the prevalence threshold using 0.05 (5%) as the standard.

```{r PrevalenceFiltering-31}
pthresh <- 0.1
```

This is around `r round(pthresh * nsamples(physeq0))` samples.  We can modify this setting, but we'll leave as is for now.  We may want to modify this to not reflect the specific group but the treatments (e.g. ensure we're not losing any taxa based on the treatment condition)

This plot shows the fraction of samples vs the total abundance for that, which helps give some idea on what to retain.

```{r PrevalenceFiltering-32 }
ggplot(prevdf,
       aes(TotalAbundance, Prevalence / nsamples(physeq0), color = Phylum)) +
  geom_hline(yintercept = pthresh, alpha = 0.5, linetype = 2) +
  geom_point(size = 2, alpha = 0.4) +
  scale_x_log10() +
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position = "none")
```

The horizontal line indicates the cutoff in this case. Let's apply it and see what happens. 

```{r PrevalenceFiltering-33 }
prevThreshold <- pthresh * nsamples(physeq.glom)

keepTaxa <- rownames(prevdf)[(prevdf$Prevalence >= prevThreshold)]
physeq.prev <- prune_taxa(keepTaxa, physeq.glom)
physeq.prev
```

This keeps quite a bit at the family level.  How does this affect counts?

```{r PrevalenceFiltering-34 }
p <- ggplot(data = data.frame(
    SampleLoss = sample_sums(physeq.prev) / sample_sums(physeq.glom),
    Names = factor(sample_names(physeq.prev), ordered = TRUE, levels = sample_names(physeq.prev)),
    Group = factor(sample_data(physeq.prev)$Strain, ordered = TRUE)
), aes(y = SampleLoss, x = Names, fill = Group))
p <- p + geom_bar(stat = 'identity' )
p <- p + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p
```

This retain the vast majority of data.  We can also try moving the agglomeration step *after* prevalence filtering, though this doesn't seem to make a significant difference.

# Save

We'll save at this stage, and then reload the data for diversity analysis and differential abundance.

```{r PrevalenceFiltering-35 }
# Save
if (!file.exists('../results/PrevalenceFiltering/')){
    dir.create(file.path('../results/PrevalenceFiltering/'), recursive = TRUE)
}
saveRDS(physeq.prev, file = "../results/PrevalenceFiltering/phyloseq.prevfiltered.RDS")
```

# Session information

```{r PrevalenceFiltering-36 }
sessionInfo()
```

