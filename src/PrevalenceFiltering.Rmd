```{r, include=FALSE}
source("~/research/biotech/young-chae_kim/2021-Fall-Microbiome/src/common_code.R", local = knitr::knit_global())
```

```{r}
physeq.filtered <- readRDS('~/research/biotech/young-chae_kim/2021-Fall-Microbiome/results/physeq.filtered.RDS')
```

# Prevalence filtering

For beta diversity we perform initial prevalence filtering and agglomeration (either tip or taxonomic rank-based)

## Additional Filtering

We performed some high level filtering to remove artifacts and problematic data. Next step is agglomeration of count data and prevalence filtering.

### Explore taxon data 

What is the range in total counts per taxon?

```{r PrevalenceFiltering-8 }
range(taxa_sums(physeq.filtered))
```

Some taxa with very low counts overall; depending on their prevalence this may be removed.  What does the distribution look like at the low end?

```{r PrevalenceFiltering-9 }
hist(log2(taxa_sums(physeq.filtered)), 1000)
```

What about sample counts?  What is the range in total counts per sample?

```{r PrevalenceFiltering-10 }
range(sample_sums(physeq.filtered))
```

We have some on the low end, with `r sum(sample_sums(physeq.filtered) <= 5000)` samples less than 5k counts.

```{r PrevalenceFiltering-11 }
p <- ggplot(data = data.frame(
    SampleSums = sample_sums(physeq.filtered),
    Names = factor(sample_names(physeq.filtered), ordered = TRUE,
                   levels = sample_names(physeq.filtered)),
    Group = factor(sample_data(physeq.filtered)$Strain, ordered = TRUE)
), aes(y = SampleSums, x = Names, fill = Group))
p <- p + geom_bar(stat = 'identity' )
p <- p + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p
```

How do the ASV counts correlate with the read counts?

```{r PrevalenceFiltering-12 }
myData <- data.frame(
  Name = sample_names(physeq.filtered),
  OTUSums = sample_sums(physeq.filtered),
  Reads = as.numeric(sample_data(physeq.filtered)$input),
  Group = sample_data(physeq.filtered)$Strain
)
p <- ggplot(data = myData, aes(x = Reads, y = OTUSums))
p <- p + geom_smooth(method = "gam", color = "lightgreen")
p <- p + geom_smooth(method = "lm", color = "lightblue")
p <- p + geom_point(aes(color = Group))
p
```

These are very clean, much cleaner than if we used R1 and R2.

Next we filter based on the features prevalent in the samples.  We will also switch the order of the filtering and tree-based (tip) agglomeration steps due to the nature of PacBio data (noisier at the tips); this is something we're discussing within the group. It may be strain-level variation that is difficult to assign.

### Tip agglomeration

What does the current tree look like?

```{r PrevalenceFiltering-13}
p <- plot_tree(physeq.filtered, 
          nodelabf = nodeplotblank, 
          color="Sample", 
          ladderize = "left", 
          method = "treeonly") +
  ggtitle(paste0("Original tree: ", ntaxa(physeq.filtered), " taxa")) +
  theme(plot.title = element_text(size = 10))
library(plotly)

ggplotly(p)
```

Zooming into the tips indicates there are a many sequences with very small differences.  

```{r PrevalenceFiltering-14}
hist(log(phy_tree(physeq.filtered)$edge.length), 
     xlab = "Edge Length (log)", 
     main = "Edge length distribution")
```

#### Clip out long branches

There are a few long branches that we need to check.  You have to zoom into the right a bit and look at the frequencies accordingly:

```{r PrevalenceFiltering-14.B}
tmp <- phy_tree(physeq.filtered)

# grab the tip lengths and format for ggplot
treeTips <- data.frame(
  ID = tmp$tip.label,
  Tip.Length = tmp$edge.length[tmp$edge[,2] <= Ntip(tmp)]
)

p <- treeTips %>%
  ggplot( aes(x=Tip.Length, fill = "black")) +
  geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity', bins = 100)

ggplotly(p + xlim(0.1, 1) + ylim(0,10))
```

Several stand out with very long tip lengths. What are they?

```{r}
longbranch <- treeTips[order(treeTips$Tip.Length, decreasing = TRUE)[1:31],]

tmp2 <- cbind(tax_table(physeq.filtered), as.data.frame(taxa_sums(physeq.filtered)))

knitr::kable(tmp2[longbranch$ID,])
```

These look real! I think we leave them as is.

What samples are these in?

```{r}
tmp <-suppressWarnings(prune_taxa(taxa_names(physeq.filtered) %in% longbranch$ID,
                  physeq.filtered))

ssums <- sample_sums(tmp)
ssums[ssums > 0]
```

They are spread across samples as well.

### Plot cophenetic distances

Agglomeration is based on the cophenetic distance, the pairwise distances between tips on the tree. These are pretty short; let's see what that distribution looks like

```{r PrevalenceFiltering-15}
cp_phylo <- cophenetic.phylo(phy_tree(physeq.filtered))

hist(cp_phylo, 
     breaks = 100, 
     main = "Pairwise distance between tips", 
     xlab = "Distance between tips")

cutoff <- c(seq(0.025, 0.15, 0.025), 0.2, 0.3, 0.5, 0.75, 1, 2)
abline(v=cutoff, col = "red")
text(cutoff, max(hist(cp_phylo, 100, plot=FALSE)$counts), labels = cutoff, pos = 2, srt = 90, cex = .5 )
```

Note those at the high end of distance, probably out off-shoot group. We do not see those in the merged data!

The red lines are some arbitrary test cutoffs. Based on the above we could use 0.3 (right after the small shoulder to the far left).  There are additional valleys around 0.5 and higher, but we could stay with the above threshold for now.

Let's replot in log scale.  

```{r PrevalenceFiltering-16}
hist(log(cp_phylo), 
     breaks = 100, 
     main = "Pairwise distance between tips", 
     xlab = "Distance between tips (log)", 
     xlim = c(-5, 5))

abline(v=log(cutoff), col = "red")
text(log(cutoff), max(hist(log(cp_phylo), 100, plot=FALSE)$counts), labels = cutoff, pos = 2, srt = 90, cex = .5 )
```

I think 0.3 or 0.5 is fine for now if we choose tip agglomeration.

```{r PrevalenceFiltering-22}
# pseqs <- lapply(cutoff[1:8], function(x) {speedyseq::tip_glom(physeq.filtered, h = x)})
physeq.glom <- tip_glom(physeq.filtered, h = 0.3)
physeq.glom
```

### Tax agglomeration

What is the effect of taxonomic agglomeration per rank? Let's do a quick run through on the samples; ranks that are not assigned are removed by default, so let's see what happens.

```{r PrevalenceFiltering-23 }
taxglom_per_rank = function(physeq.glom, rank = "Species") {
  # TODO: add sanity check
  glommedPhyseq <- tax_glom(physeq.glom, taxrank = rank, NArm = TRUE)
  p <- ggplot(data = data.frame(
      SampleLoss = sample_sums(glommedPhyseq) / sample_sums(physeq.filtered),
      Names = factor(sample_names(glommedPhyseq),
                     ordered = TRUE,
                     levels = sample_names(glommedPhyseq)),
      Group = factor(sample_data(glommedPhyseq)$Strain, ordered = TRUE)
  ), aes(y = SampleLoss, x = Names, fill = Group)) +
    geom_bar(stat = 'identity' ) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    ggtitle(paste0("Rank: ", rank))
  return(p)
}
```

```{r PrevalenceFiltering-24 }
tmp <- as(tax_table(physeq.filtered), 'matrix')
tmp[tmp == 'Unclassified'] = NA
tax_table(physeq.filtered) <- tmp
```

```{r}
ranks <- c("Species", "Genus", "Family", "Order")

plots <- lapply(ranks, function(x) {
  p <- taxglom_per_rank(physeq.filtered, rank = x)
  p + theme(legend.position = "none") + expand_limits(y = c(0, 1))
})

grid.arrange(grobs = plots)
```

Quite a bit lost with species and genus, not atypical for short fragments unfortunately.  Are there rows in there with 'NA'?

```{r PrevalenceFiltering-25 }
#apply(tax_table(physeq.glom), 2, function(x) sum(x != "Unclassified"))
apply(tax_table(physeq.filtered), 2, function(x) sum(is.na(x)))
```

A steep increase in unassigned ranks from Family to Genus. If we stick to family we retain most information.  If we choose taxonomic agglomeration, I'll likely agglomerate to Family simply due to the resolution, but we can revisit.

<!-- Yes, though not nearly as many as the overall # of taxa. This suggests maybe using the phylogenetic tree and `tip_glom`. We have been seeing this work with better fidelity with more recent data sets, particularly from PacBio sequences, but it does require a little checking on the phylogenetic branch lengths to determine the best cutoff.  The code below is based on work Lindsay Clark and Jenny have done in the group.  -->

<!-- ## Tree glom  -->

<!-- This is a newer but somewhat experimental method implemented in the `speedyseq` package. -->

<!-- ```{r} -->
<!-- #get_pairwise_distances(tree, A, B, as_edge_counts=FALSE, check_input=TRUE) -->
<!-- ``` -->

```{r}
# physeq.glom <- tax_glom(physeq.filtered, taxrank = 'Family', NArm = FALSE)
# physeq.glom
```

## Features and Prevalence tables

For the filtering, let's assign the original filtered data to a temp variable prior to prevalence filtering.  Here we are using the tip agglomerated data

```{r PrevalenceFiltering-26 }
physeq0 <- physeq.glom
physeq0
```

Suggested based on the Callahan dada2 workflow (F1000Research, 2017).  This is a bit of data exploration to see how many features are present per taxa.

```{r PrevalenceFiltering-27 }
table(tax_table(physeq0)[,"Phylum"], exclude = NULL)
```

A number of ASVs at the Phylum level are 'NA', not unusual as we're using tip agglomoeration but also largely uninformative.  There are number with low features (1-2 OTUs) as well. Let's remove the NA taxa...

```{r PrevalenceFiltering-28 }
physeq0 <- subset_taxa(physeq0, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
physeq0
```

There is a small difference here. 

Now, let's get an idea how many taxa in the samples have an ASV count greater than 1.  We can make this more or less strict as needed.

```{r PrevalenceFiltering-29 }
# What is this doing?  It calculates a vector with the count being the # samples with a count > 0.

# Note: make sure you are using *raw counts* here; if you use proportional
# counts make sure to adjust the function appropriately
prevdf <- apply(otu_table(physeq0),  # counts
               # use row or column depending on the data
               MARGIN = ifelse(taxa_are_rows(physeq0), yes = 1, no = 2), 
               # how many times the counts in the samples are greater than 0
               FUN = function(x){sum(x > 0)}  
               )
prevdf <- data.frame(Prevalence =  prevdf, # num samples counts are > 0
                     TotalAbundance = taxa_sums(physeq0), # total abundance
                     tax_table(physeq0)) # tax ID and ranks
```

Here is a quick summary of the prevalence results.  These are performed per ASV but summarized at the Phylum rank, with the 

```{r PrevalenceFiltering-30 }
# a quick high level summary at the Phylum rank.
tmp <- plyr::ddply(prevdf, "Phylum", function(df1) { cbind(mean(df1$Prevalence), sum(df1$Prevalence)) })
colnames(tmp) <- c("Phylum", "mean", "sum")
knitr::kable(tmp)
```

Actinos, Proteos, Firmicutes,and Bacteroidota; the usual suspects.  We can plot these out to get more resolution.  Let's graph the prevalence threshold using 0.05 (5%) as the standard.

```{r PrevalenceFiltering-31}
pthresh <- 0.1
```

This is around `r round(pthresh * nsamples(physeq0))` samples.  We can modify this setting, but we'll leave as is for now.  We may want to modify this to not reflect the specific group but the treatments (e.g. ensure we're not losing any taxa based on the treatment condition)

This plot shows the fraction of samples vs the total abundance for that, which helps give some idea on what to retain.

```{r PrevalenceFiltering-32 }
ggplot(prevdf,
       aes(TotalAbundance, Prevalence / nsamples(physeq0), color = Phylum)) +
  geom_hline(yintercept = pthresh, alpha = 0.5, linetype = 2) +
  geom_point(size = 2, alpha = 0.4) +
  scale_x_log10() +
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position = "none")
```

The horizontal line indicates the cutoff in this case. Let's apply it and see what happens. 

```{r PrevalenceFiltering-33 }
prevThreshold <- pthresh * nsamples(physeq.glom)

keepTaxa <- rownames(prevdf)[(prevdf$Prevalence >= prevThreshold)]
physeq.prev <- prune_taxa(keepTaxa, physeq.glom)
physeq.prev
```

This keeps quite a bit at the family level.  How does this affect counts?

```{r PrevalenceFiltering-34 }
p <- ggplot(data = data.frame(
    SampleLoss = sample_sums(physeq.prev) / sample_sums(physeq.glom),
    Names = factor(sample_names(physeq.prev), ordered = TRUE, levels = sample_names(physeq.prev)),
    Group = factor(sample_data(physeq.prev)$Strain, ordered = TRUE)
), aes(y = SampleLoss, x = Names, fill = Group))
p <- p + geom_bar(stat = 'identity' )
p <- p + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p
```

This retain the majority of data (~90% or so)  We can also try moving the agglomeration step *after* prevalence filtering, though this doesn't seem to make a significant difference.

```{r PrevalenceFiltering-35 }
saveRDS(physeq.prev, file = "~/research/biotech/young-chae_kim/2021-Fall-Microbiome/results/phyloseq.prevfiltered.RDS")
```

